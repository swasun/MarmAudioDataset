{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marmaudio.denoise import denoise\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchaudio.transforms as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define spectrogram functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spectrogram(waveform):\n",
    "    spectrogram = T.Spectrogram(n_fft=512)\n",
    "    spec = spectrogram(torch.from_numpy(waveform))\n",
    "    return spec\n",
    "\n",
    "def plot_spectrogram(specgram, title=None, ylabel=\"Frequency (kHz)\", xlabel=\"Time (s)\", sampling_rate=96000, ax=None):\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    num_frames, num_bins = specgram.shape\n",
    "    times = np.arange(num_frames) * (num_bins / float(sampling_rate))\n",
    "    frequencies = np.linspace(0, sampling_rate / 2000, num=specgram.shape[0], endpoint=False)\n",
    "    \n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "\n",
    "    ax.imshow(librosa.power_to_db(specgram), origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\",\n",
    "              extent=[times[0], times[-1], frequencies[0], frequencies[-1]])\n",
    "    ax.set_aspect('auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Annotations.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sample a vocalization for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row = df.sample(n=1)\n",
    "file_id = random_row.index[0]\n",
    "file_path = os.path.join('Vocalizations', random_row[\"parent_name\"].item(), random_row[\"file_name\"].item())\n",
    "signal, sampling_rate = sf.read(file_path) # Read the vocalization waveform and store it as 'signal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally denoise the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_signal = denoise(signal, sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the vocalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = make_spectrogram(signal)\n",
    "denoised_spec = make_spectrogram(denoised_signal)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "plot_spectrogram(spec, title=random_row.file_name.item(), ax=axes[0])\n",
    "plot_spectrogram(denoised_spec, title='Denoised', ax=axes[1])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
